<!DOCTYPE html>
<html lang="en">
	<!--Set up page-->
	<head>
		<meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link rel="stylesheet" href="style.css">
    <title>Aasha's Portfolio</title>
		<!--Inserting and formatting background image-->
		<style>
			body {
				/*--background-image: url('images/Bluffs.jpg');-->*/
				background-color: #1e2328;
				background-repeat: no-repeat;
				background-size: cover;
				background-position: center center;
				background-attachment: fixed;
			}
		</style>
  </head>

  <!--Navigation bar-->
  <div class="navbar">
			<div class="navbar-right">
      <a href="./index.html">Home</a>
			<a href="./resume.html">Resume</a>
			<a href="./projects.html" class="active">Projects & Research</a>
			<!--<a href="./contact.html">Contact</a>-->
		</div>
</div>

<div class="essay">
<body>
  <img src="./images/Social-Media-Header-Image.jpg" alt="silhouettes of a faces" id="header_img">
  <h1>Social Media or Social Exploitation?</h1>
  <p> “We’re Updating Our Terms and Privacy Policy…” is all social media users see before scrolling
    to the bottom and clicking the bold and bright “Accept” button to get their hourly dose of likes,
    comments and shares on Facebook. It is at this moment that users could unknowingly barter their
    data with corporations to engage in online social interaction. Social platforms like Instagram or
    Facebook provide vague details to users about how their data is used by employing a similar tactic
    that lawyers utilize to share evidence with their opposition: overwhelming the receiver with a
    large amount of information in order to discourage them by the length of time it will take to read
    through the information. This is one of many ways that contribute to the lack of awareness and the
    power imbalance between companies that collect, sort and distribute data and those who unwittingly
    volunteer access to their data. In 2018, a political consulting firm, Cambridge Analytica, collected
    personally identifiable information for up to 87 million Facebook users, partially due to users
    unknowingly accepting broad terms and conditions, to build voter profiles for the 2020 U.S.
    Presidential Election Republican Candidate Donald Trump (TechRepublic and Confessore). Social media
    users should be provided opportunities for fully informed consent in not just what data is collected,
    analyzed and interpreted but how that data is specifically used for or against them, in order to
    assess whether or not they need justice for how their data is bartered.</p>
  <p>The purpose of bartering is for platform owners to regularly sell users’ metadata with third-party
    vendors in order to create targeted marketing toward users (van Djick 197). Bartering is promoted by
    dataism, which is the belief in potential tracking and objective quantification of human behavior and
    sociality through online media applications (van Djick 201). Dataism is driven by the political agenda
    of platform owners who is it for their financial gain, which essentially provides no benefit to the users.
    If the users are not benefiting from the exchange of their data for social interaction, they become victims
    of data injustice.</p>
    <p>Data justice refers to the recognition of “the political economy of the system that underpins the
       possibilities for extensive surveillance, whilst drawing attention to the political agenda that is
       driving its implementation,” (Dencik 10). Therein lies the issue that there is a specific lack of
       attention by users to the political agenda of lucrative social media bartering. In order to draw focus
       to this selfish intention professor Linnet Taylor proposed a conceptual data justice framework, which is
       composed of three pillars: visibility, non-discrimination and (dis)engagement with technology (Taylor 8).</p>
    <p>With visibility in data justice, comes access to representation and information privacy. Users must
      consider how they are represented and protected in their bartered data through datafication, which is
      the “transformation of social action into online quantified data,” (van Djick 205). Regarding the type of
      user data collected: identifiable information such as email addresses, phone numbers, full name, age,
      gender, nationality and ethnicity are personally identifiable information that could be sold to third parties
      like retail companies and the government to endanger user privacy and security. Retail companies can use this
      information to develop targeted marketing strategies for a specific set of social media users. The government
      can use private information to track online activity and create predictive algorithms to guess whether someone
      could engage in unlawful behavior. The government’s regular monitoring of users’ metadata gathered from online
      media technologies for “unstated preset purposes” is known as “dataveillance,” (van Djick 205). Using predictive
      algorithms that feed on age, gender, nationality and ethnicity data mirrors discrimination tactics that facial
      recognition software used to determine suspects because the data provided is inherently racially biased. This
      biased data cannot serve justice until the social justice movement and justice departments can eradicate systemic
      racial prejudice from the legal system.</p>
    <p>The issue of discrimination in data is rather popular because much data analyzed by algorithms and other
      software use biased data. Taylor proposes that users need the ability to challenge such biases to prevent
      further discrimination, especially in regard to dataveillance. Dataveillance has become a normal part of social
      media, and the discrimination that comes with it is normalized due to the popularization of datafication as an
      objective model paired with a strong belief in dataism (van Djick 206). There is a lack of trust between users and
      platforms, and without trust, datafication would lose its popularity. This blind trust of users stems from their lack
      of awareness – by not reading or skipping through the updated terms and conditions of companies. Users disregard how
      their data is collected, analyzed and interpreted by third parties who buy user data from platform owners.
      If platform owners wish to collect user data, they should at least clarify the utilization of user data. </p>
    <p>Social media user engagement needs to be balanced with their right to autonomy and data privacy. If users can opt-in
        to share their data with platforms, they should also reserve the right to disengage – or, opt out of sharing their data.
        As the age of technology integrates more into daily online social activities, the lines of data privacy become more blurred.
        Users connect with others through social media for personal enjoyment, not for the financial gains of platform owners.
        There have been no clear benefits toward users based on their researched metadata other than customized marketing to
        increase profits for platform owners in Silicon Valley, which is an example of a targeting tactic for increasing profits
        in the corporate sector (van Djick 203).</p>
    <p> These lack of user benefits from social media bartering go unnoticed because users do not realize that their data should
      be used for their benefit, not as a benefit to the platforms they are supposed to trust with their data. According to van Djick,
      he expresses that it is “crucial to render hidden prerogatives explicit if researchers want to keep up users’ trust in the
      datafication paradigm,”  (202). That is to say within the realm of datafication, “identifying meaningful patterns on the basis
      of data culled from online platforms is an intrinsically interpretive act, although you may have to spell out implicit
      prerogatives,” (van Djick 202). Platform owners and researchers need to maintain an honest bridge of transparency to prevent
      further exploitation of user metadata. In order for users to determine whether or not an online media platform satisfies a
      demand for data justice, they must have access to this bridge in order to clearly see the realm of datafication that lingers
      through their online lives. Lastly, The concept of social media bartering is a prominent situation in which data cannot serve
      justice until all platform owners implement Taylor’s data justice framework.</p>
</body>
</div>

</html>
